{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxwell A. Fine 2024-07-10\n",
    "\n",
    "This notebook is trying out running `predict.py` from [fetch](https://github.com/devanshkv/fetch/tree/tf2) within a python script, as well as moving the 'good' candidates into another dir and making diagnostic `.png` files. \n",
    "\n",
    "### Fetch\n",
    "`Fetch` is a machine learning approach to identifying real and RFI pulse candidates, see the paper [here](https://arxiv.org/abs/1902.06343).\n",
    "\n",
    "The `Fetch` package on github comes all set with a script `predict.py` that works on `.h5` files of a predetermined shape.It needs a `--datadir`, and a `--model` key flag argument to run. The output is a `.csv` file containg if the candidate file with the labeles as classified by fetch (1=good, 0=bad).\n",
    "\n",
    "`Fetch` runs on a GPU, using CUDA. \n",
    "\n",
    "\n",
    "### Task:\n",
    "I want to run `fetch` from inside another python script. This gives us two possibiltiies:\n",
    "- write a simple `subprocess` command to execute the script\n",
    "- import the required functions to run the `main` function in `predict.py` and use it natively in python\n",
    "\n",
    "\n",
    "### Notes From my use of `fetch` so far:\n",
    "- There is a comparably long start up time when running, I think its involved in setting up the GPU and moving over the data? \n",
    "- Fetch runs pretty fast per itertation, ~800-1000 candidates / minute. \n",
    "\n",
    "\n",
    "### Idea:\n",
    "- It is probablly more **pythonic** to import the functions to run `fetch` inside of another script, but running it via a `subprocess` call is faster to implement, and will perform about the same. Since the pipeline already is making `subprocess` calls, I will do it with this method. \n",
    "    - using a `subproccess` call might be better for other users for future improvements, as it would use all the same commands as `predict.py`\n",
    "\n",
    "- We could cut out much of the start up time, by running `fetch` just once per observation (as opposed to once per `.fil` file). But then we couldn't run the pipeline in **real** time. I favor running it in real time, so we will run it once per `.fil` file.\n",
    "    - The pipeline is running parallel, how does our GPU handle it?\n",
    "\n",
    "- there already exists a `move_candidates.py` script in [pipeline gitlab repo code](https://gitlab.camras.nl/dijkema/frbscripts)\n",
    "    - I can maybe make a wrapper function around this, and then just import it in the `check_frb.py` script\n",
    "- similariy, use the `plot_h5` code (more of a call to another function) to do the plotting of diagnostic plots\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from move_candidates import move_candidates # modified \n",
    "from plot_h5 import process_files_in_parallel # modified \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)\n",
    "\n",
    "def run_predict_and_move(data_dir, model='a'):\n",
    "    '''\n",
    "    Runs the `fetch` program `predict.py` using a subprocess call in /process, and then moves\n",
    "    the candiate files into a /process/good, and /process/bad directory based on the prediction. \n",
    "    Diagnostic png plots are produced from the `.h5` files in the /process/good dir. \n",
    "\n",
    "    Args:\n",
    "    data_dir: (str), the data_dir argument for `predict.py`, it should be the /process dir if using `check_frb.py`\n",
    "    \n",
    "    model: (str), the model argument for `predict.py`, default is 'a'.\n",
    "    '''\n",
    "    # Define the paths to the scripts\n",
    "    \n",
    "    predict_script = \"predict.py\"\n",
    "    \n",
    "    # Arguments for predict.py\n",
    "    # Has to be run in the /process dir\n",
    "    predict_args = [\n",
    "        predict_script,\n",
    "        \"-c\", data_dir,\n",
    "        \"-m\", model,\n",
    "        \"--verbose\"\n",
    "    ]\n",
    "\n",
    "    # Run predict.py\n",
    "    print('Running predict.py (fetch)')\n",
    "    result = subprocess.run(predict_args, capture_output=True , text=True)\n",
    "    # TODO Max Fine Jul 10 2024, this works but it would be nice if stdout was printed as it was made\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running predict.py: {result.stderr}\")\n",
    "        return\n",
    "    else:\n",
    "        print(result.stdout) \n",
    "        \n",
    "        # Move Candidates into /good and /bad\n",
    "        move_candidates() # Has to be run in the /process dir\n",
    "\n",
    "        # make .h5 files in the good directory to .png\n",
    "        good_dir = os.path.join(data_dir, \"good\")\n",
    "        good_h5_files = [os.path.join(good_dir, f) for f in os.listdir(good_dir) if f.endswith('.h5')]\n",
    "        if good_h5_files:\n",
    "            print(f'Converting {len(good_h5_files)} .h5 files to .png')\n",
    "            process_files_in_parallel(good_h5_files)\n",
    "        else:\n",
    "            print(\"No .h5 files found in the good directory to convert.\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predict.py (fetch)\n",
      "\n",
      "1/1 [==============================] - ETA: \n",
      "1/1 [==============================] - 5s 5s/step\n",
      "\n",
      "No .h5 files found in the good directory to convert.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "data_dir = '/data/frb/maxfinetmp/process/bad'\n",
    "run_predict_and_move(data_dir, \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run in module subprocess:\n",
      "\n",
      "run(*popenargs, input=None, capture_output=False, timeout=None, check=False, **kwargs)\n",
      "    Run command with arguments and return a CompletedProcess instance.\n",
      "    \n",
      "    The returned instance will have attributes args, returncode, stdout and\n",
      "    stderr. By default, stdout and stderr are not captured, and those attributes\n",
      "    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,\n",
      "    or pass capture_output=True to capture both.\n",
      "    \n",
      "    If check is True and the exit code was non-zero, it raises a\n",
      "    CalledProcessError. The CalledProcessError object will have the return code\n",
      "    in the returncode attribute, and output & stderr attributes if those streams\n",
      "    were captured.\n",
      "    \n",
      "    If timeout is given, and the process takes too long, a TimeoutExpired\n",
      "    exception will be raised.\n",
      "    \n",
      "    There is an optional argument \"input\", allowing you to\n",
      "    pass bytes or a string to the subprocess's stdin.  If you use this argument\n",
      "    you may not also use the Popen constructor's \"stdin\" argument, as\n",
      "    it will be used internally.\n",
      "    \n",
      "    By default, all communication is in bytes, and therefore any \"input\" should\n",
      "    be bytes, and the stdout and stderr will be bytes. If in text mode, any\n",
      "    \"input\" should be a string, and stdout and stderr will be strings decoded\n",
      "    according to locale encoding, or by \"encoding\" if set. Text mode is\n",
      "    triggered by setting any of text, encoding, errors or universal_newlines.\n",
      "    \n",
      "    The other arguments are the same as for the Popen constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(subprocess.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch_python.ipynb  \u001b[0m\u001b[01;32mmove_candidates.py\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run in module subprocess:\n",
      "\n",
      "run(*popenargs, input=None, capture_output=False, timeout=None, check=False, **kwargs)\n",
      "    Run command with arguments and return a CompletedProcess instance.\n",
      "    \n",
      "    The returned instance will have attributes args, returncode, stdout and\n",
      "    stderr. By default, stdout and stderr are not captured, and those attributes\n",
      "    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them,\n",
      "    or pass capture_output=True to capture both.\n",
      "    \n",
      "    If check is True and the exit code was non-zero, it raises a\n",
      "    CalledProcessError. The CalledProcessError object will have the return code\n",
      "    in the returncode attribute, and output & stderr attributes if those streams\n",
      "    were captured.\n",
      "    \n",
      "    If timeout is given, and the process takes too long, a TimeoutExpired\n",
      "    exception will be raised.\n",
      "    \n",
      "    There is an optional argument \"input\", allowing you to\n",
      "    pass bytes or a string to the subprocess's stdin.  If you use this argument\n",
      "    you may not also use the Popen constructor's \"stdin\" argument, as\n",
      "    it will be used internally.\n",
      "    \n",
      "    By default, all communication is in bytes, and therefore any \"input\" should\n",
      "    be bytes, and the stdout and stderr will be bytes. If in text mode, any\n",
      "    \"input\" should be a string, and stdout and stderr will be strings decoded\n",
      "    according to locale encoding, or by \"encoding\" if set. Text mode is\n",
      "    triggered by setting any of text, encoding, errors or universal_newlines.\n",
      "    \n",
      "    The other arguments are the same as for the Popen constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(subprocess.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/frb/maxfinetmp/process/bad'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/frb/maxfinetmp/process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home_local/frb/venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "cd /home_local/frb/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home_local/maxfine/subproccess_fetch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home_local/frb/venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /home_local/maxfine/subproccess_fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home_local/maxfine/subproccess_fetch'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
