{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc6a913-56bb-49a8-98e3-2458962a006b",
   "metadata": {},
   "source": [
    "### Maxwell A. Fine 2024-07-30\n",
    "\n",
    "This notebook serves as an updated way of recording and slicing sigmf (baseband) data\n",
    "\n",
    "We use:\n",
    "`test_recording_baseband_data.ipynb` and `crop_sigmf.py` as our starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d77817-74b7-4d18-8a64-20f4b98693c5",
   "metadata": {},
   "source": [
    "\n",
    "### `crop_sigmf(input_metafilename, output_metafilename, start_s, duration_s)`\n",
    "\n",
    "Takes in input filename, outputfile name, \n",
    "\n",
    "start_s is the time of the candidate in seconds since the start of the sigmf file\n",
    "\n",
    "duration_s is how long to slice out\n",
    "\n",
    "### Challenge:\n",
    "* we must get set start_s, and make the filenames\n",
    "\n",
    "### Notes:\n",
    "* use `astropy` for time conversions, not `datetime` (silly me~)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401dd513-02f4-4fec-9d41-19e919dda870",
   "metadata": {},
   "source": [
    "### This will be extremely ugly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffabe12-dc3b-442a-970f-6bbb45cbcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from crop_sigmf import crop_sigmf\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sigmf\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "from astropy.time import Time\n",
    "from your.formats.pysigproc import SigprocFile\n",
    "fromisoformat = datetime.fromisoformat\n",
    "import json\n",
    "import pytz  # time zone management "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306c417-c6bb-4410-b5d2-02a4d97b81c5",
   "metadata": {},
   "source": [
    "### Function to read in meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00a33df-ec74-4b35-a722-d644dec3b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baseband_data(ram_data_dir, orig_file_name, return_data=False, data_slice=False):\n",
    "    \"\"\"\n",
    "    Reads metadata from a baseband data file and extracts key information.\n",
    "\n",
    "    Parameters:\n",
    "    ram_data_dir (str): Directory where the baseband data file is stored.\n",
    "    orig_file_name (str): Name of the baseband data file including the `.sigmf-meta` extension. \n",
    "    return_data (bool, optional): If True, additional data will be returned. Defaults to False.\n",
    "    data_slice (bool, optional): If True, a slice of the data will be returned. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains the sample rate (float), highest frequency (float, in MHz), \n",
    "           start time (str, in ISO format), and version (str, dummy value).\n",
    "    \"\"\"\n",
    "    with open(os.path.join(ram_data_dir, orig_file_name), \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        \n",
    "    sample_rate = metadata[\"global\"][\"core:sample_rate\"]\n",
    "\n",
    "    start_time_str = metadata[\"captures\"][0][\"core:datetime\"] # iso \n",
    "    start_time = start_time_str #iso\n",
    "    version = '1' # dummy \n",
    "    highest_freq  = metadata['captures'][0]['core:frequency']* 1e-6 # mhz#: \n",
    "\n",
    "    return sample_rate, highest_freq, start_time, version\n",
    "\n",
    "\n",
    "def get_number_of_samples_from_sigmf(filepath, sample_dtype=np.complex64, file_extension='.sigmf-data', ram_data_dir='/data_tmp'):\n",
    "    \"\"\"\n",
    "    Calculate the number of samples in a SigMF binary data file.\n",
    "\n",
    "    This function reads the size of the binary data file associated with the given\n",
    "    SigMF filepath and calculates the number of samples based on the specified\n",
    "    sample data type.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The base filepath (without the extension) of the SigMF file. The function\n",
    "        expects the binary data file to have a '.sigmf-data' extension.\n",
    "    sample_dtype : numpy.dtype, optional\n",
    "        The data type of the samples in the binary file. Default is np.complex64.\n",
    "    file_extension : str, optional \n",
    "        File extension to add, default is '.sigmf-data'\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    int\n",
    "        The number of samples in the binary data file.\n",
    "    \"\"\"\n",
    "    base, ext = os.path.splitext(filepath)\n",
    "    data_file = base + file_extension\n",
    "    data_file = os.path.join(ram_data_dir, data_file)\n",
    "    file_size = os.path.getsize(data_file)\n",
    "    sample_size = np.dtype(sample_dtype).itemsize\n",
    "    num_samples = file_size // sample_size\n",
    "    return num_samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c3289-d50c-413a-9f43-d9fec4a12d92",
   "metadata": {},
   "source": [
    "###  Functions to adjust candidate time for arrival time delay\n",
    "\n",
    "\n",
    "### New functions for computing arrival time \n",
    "\n",
    "\n",
    "$$ \\Delta T = \\mathrm{Constant} * DM (\\frac{1}{f_{\\mathrm{1}}^2} - \\frac{1}{f_{\\mathrm{2}}^2})$$\n",
    "\n",
    "\n",
    "-  aka t2 – t1 = 4.15 ms DM [( ν1 /GHz)-2 – ( ν2 /GHz)-2]\n",
    "- t2 -t1 \n",
    "- f_low - f_high\n",
    "- DM = Col mass of free elections [pc/cm^3]\n",
    "- Constant = 4.15ms for freq units in Ghz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4804c85-f90b-43a8-b1ae-e7fe30acdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_t(DM, freq1, freq2, time1, time2, constant=4.149e-3):\n",
    "    \"\"\"\n",
    "    Calculates the time delay between two frequencies due to dispersion.\n",
    "\n",
    "    Parameters:\n",
    "    DM (float): Dispersion measure in pc/cm^3.\n",
    "    freq1 (float): First frequency in GHz.\n",
    "    freq2 (float): Second frequency in GHz.\n",
    "    time1 (float): Time at first frequency (not used in calculation).\n",
    "    time2 (float): Time at second frequency (not used in calculation).\n",
    "    constant (float, optional): Constant used in the dispersion formula, defaults to 4.149e-3\n",
    "\n",
    "    Returns:\n",
    "    float: Arrival Time delay in seconds between the freq1 and freq2.\n",
    "    \"\"\"\n",
    "    DM = float(DM)\n",
    "\n",
    "    delta_t = constant*DM* ((1/freq1)**2 - (1/freq2)**2) \n",
    "    print(f'Correction in seconds: {delta_t}')\n",
    "    return delta_t # seconds\n",
    "\n",
    "def mjd_from_iso(iso_time):\n",
    "    'Convert ISO time to MJD using astropy time'\n",
    "    \n",
    "    t = Time(iso_time, format='isot', scale='utc')\n",
    "    \n",
    "    return t.mjd\n",
    "\n",
    "def compute_time_offset(sigmf_file1, sigmf_file2, dm, time_candidate, ram_data_dir):\n",
    "    \"\"\"\n",
    "    Computes the time offset between two signals due to dispersion measure (DM),\n",
    "    and returns an adjusted time_candidate (in mjd) for sigmf_file2\n",
    "\n",
    "    Parameters:\n",
    "    sigmf_file1 (str): The first SigMF file name (without extension).\n",
    "    sigmf_file2 (str): The second SigMF file name (without extension).\n",
    "    dm (float): Dispersion measure in pc/cm^3.\n",
    "    time_candidate (tuple): Candidate time tuple containing (stuff, MJD time) for sigmf_file1.\n",
    "    ram_data_dir (str): Directory where the SigMF files are stored.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Adjusted time candidate tuple for sigmf_file2 and the time offset in seconds.\n",
    "    \"\"\"\n",
    "    # Read metadata from both SigMF files\n",
    "    ext = '.sigmf-meta'\n",
    "    sample_rate1, center_freq1, start_time1, version1 = read_baseband_data(ram_data_dir, sigmf_file1 + ext)\n",
    "    sample_rate2, center_freq2, start_time2, version2 = read_baseband_data(ram_data_dir, sigmf_file2 + ext)\n",
    "    \n",
    "    # Compute the time offset due to dispersion measure\n",
    "    freq1 = center_freq1 * 1e-3  # Convert MHz to GHz\n",
    "    freq2 = center_freq2 * 1e-3  # Convert MHz to GHz\n",
    "    time_offset = delta_t(dm, center_freq1, center_freq2, start_time1, start_time2,)\n",
    "    \n",
    "    # Convert the start times to MJD\n",
    "    mjd_start1 = mjd_from_iso(start_time1)\n",
    "    mjd_start2 = mjd_from_iso(start_time2)\n",
    "    \n",
    "    # Adjust the time candidate\n",
    "    stuff, mjd_start1 = time_candidate\n",
    "    mjd_start2 = mjd_start1 + (time_offset / 86400.0)  # Convert seconds to days for MJD adjustment\n",
    "    \n",
    "    return (stuff, mjd_start2), time_offset\n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff18bf-c8e7-4532-90e6-1c24967cb9b3",
   "metadata": {},
   "source": [
    "### Many functions to parse h5 files, and read in time candidate, and start time of .fil file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ac16e3-7443-40b9-8dea-a0ac07fa275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_snr_and_dm_from_hdf5(file_path):\n",
    "    \"\"\"\n",
    "    Extract the Signal-to-Noise Ratio (SNR) and Dispersion Measure (DM) from the root attributes of an HDF5 file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        The path to the HDF5 file from which to extract the SNR and DM values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    snr : float\n",
    "        The Signal-to-Noise Ratio (SNR) value extracted from the root attributes of the HDF5 file.\n",
    "    dm : float\n",
    "        The optimal Dispersion Measure (DM) value extracted from the root attributes of the HDF5 file.\n",
    "\n",
    "    Raises:\n",
    "    -------\n",
    "    KeyError\n",
    "        If the 'snr' or 'dm_opt' attributes are not found in the root attributes of the HDF5 file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(file_path, 'r') as hdf:\n",
    "        # Extract and store root attributes\n",
    "        root_attrs_dict = {attr: hdf.attrs[attr] for attr in hdf.attrs.keys()}\n",
    "\n",
    "        snr = root_attrs_dict['snr']\n",
    "        dm = root_attrs_dict['dm_opt']\n",
    "\n",
    "    return snr, dm\n",
    "\n",
    "\n",
    "def parse_h5_filename(file_names):\n",
    "    \"\"\"\n",
    "    Extracts metadata from a list of HDF5 file names.\n",
    "\n",
    "    This function processes each file name in the input list to extract and return the directory, \n",
    "    basename, tcand, dm components, band, and fil_file path.\n",
    "    \n",
    "    Parameters:\n",
    "    file_names (list of str): List of full path to HDF5 file names. Each file name is expected to follow the pattern\n",
    "                              '/data/frb/date/good/basename_tcand_<tcand>_dm_<dm>_snr_<snr>.h5'.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing: file_names, (dir_name, basename, tcand, dm, band, fil_file)\n",
    "           - file_names (list of str): The original list of file names.\n",
    "           - results (list of tuples): A list of tuples where each tuple contains:\n",
    "             - dir_name (str): The directory of the file (empty string if no directory is specified).\n",
    "             - basename (str): The base name of the file up to `_tcand`.\n",
    "             - tcand (str): The tcand value extracted from the file name.\n",
    "             - dm (str): The dm value extracted from the file name.\n",
    "             - band (str): The band value extracted from the file name.\n",
    "             - fil_file (str): The corresponding fil_file path based on the extracted band.\n",
    "             - fil_start, when the fil file started in local time\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for file_name in file_names:\n",
    "        # Extract directory and base file name\n",
    "        dir_name = os.path.dirname(file_name) # the /data/frb/date/good dir\n",
    "        date_dir = os.path.dirname(dir_name) # the /data/frb/date dir\n",
    "        base_file_name = os.path.basename(file_name)\n",
    "        \n",
    "        parts = base_file_name.split('_')\n",
    "        if len(parts) >= 10 and parts[-1].endswith('.h5'):\n",
    "            basename = parts[0]\n",
    "            band = '_'.join(parts[1:3])\n",
    "            fil_start = '_'.join(parts[3:9])\n",
    "            tcand = parts[-5]\n",
    "            dm = parts[-3]\n",
    "\n",
    "            # Construct fil_file path\n",
    "            path_to_fil_file = os.path.join(date_dir, band,  f\"{basename}_{band}_{fil_start}.fil\")\n",
    "            results.append((dir_name, basename, tcand, dm, band, path_to_fil_file, fil_start))\n",
    "    \n",
    "    return file_names, results\n",
    "\n",
    "def read_fil_metadata(file_path):\n",
    "    \"\"\"\n",
    "    Reads metadata from a .fil file and returns it as a tuple.\n",
    "\n",
    "    # TODO Max Fine, I want to calculate the duration of the .fil file and return it \n",
    "    \n",
    "    Args:\n",
    "    file_path (str): The path to the .fil file.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing (tstart_mjd, basename, fch1, foff, nchans, tsamp,)\n",
    "\n",
    "    fch1 = fil.fch1  # Frequency of the first channel\n",
    "    foff = fil.foff  # Frequency offset between channels\n",
    "    nchans = fil.nchans  # Number of channels\n",
    "    tsamp = fil.tsamp  # sampling interval (seconds)\n",
    "    nbits = fil.nbits # Number of bits the data are recorded in.\n",
    "    tstart_mjd = fil.tstart  # Start time in MJD\n",
    "    \"\"\"\n",
    "    fil = SigprocFile(file_path)\n",
    "    \n",
    "    basename = os.path.basename(file_path)  # Extracting the basename of the file\n",
    "    fch1 = fil.fch1  # Frequency of the first channel\n",
    "    foff = fil.foff  # Frequency offset between channels\n",
    "    nchans = fil.nchans  # Number of channels\n",
    "    tsamp = fil.tsamp  # sampling interval (seconds)\n",
    "    nbits = fil.nbits # Number of bits the data are recorded in.\n",
    "    tstart_mjd = fil.tstart  # Start time in MJD\n",
    "\n",
    "    # Assuming fil.data is a numpy array containing the data, its size divided by nchans gives the number of samples\n",
    "    nsamples = np.shape(fil.get_data) # // nchans\n",
    "    \n",
    "    return (tstart_mjd, basename, fch1, foff, nchans, tsamp, nbits, nsamples)\n",
    "    \n",
    "\n",
    "def find_candidate_time_in_mjd_get_meta(h5_file_names):\n",
    "    \"\"\"\n",
    "    Finds the time of the candidate in MJD using metadata from both .h5 and .fil files.\n",
    "    \n",
    "    Parameters:\n",
    "    h5_file_names (list of str): List of full path to HDF5 file names.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains the file name and the candidate time in MJD.\n",
    "    \"\"\"\n",
    "\n",
    "    _, h5_metadata = parse_h5_filename(h5_file_names)\n",
    "\n",
    "    # Read metadata from .h5 header \n",
    "    snr_list = []\n",
    "    dm_list = []\n",
    "    for h5_file in h5_file_names:\n",
    "        snr, dm = extract_snr_and_dm_from_hdf5(h5_file)\n",
    "        snr_list.append(snr)\n",
    "        dm_list.append(dm)\n",
    "\n",
    "    candidate_times_mjd = []\n",
    "    for metadata in h5_metadata:\n",
    "        # Read metadata from the corresponding .fil file\n",
    "        dir_name, basename, tcand, dm, band, fil_file, fil_start = metadata  \n",
    "        tstart_mjd, fil_basename, fch1, foff, nchans, tsamp, nbits, nsamples = read_fil_metadata(fil_file)\n",
    "\n",
    "        # Calculate the time of the candidate\n",
    "        tcand = float(tcand)\n",
    "        candidate_time_mjd = tstart_mjd + (tcand ) / (24 * 3600)  # Convert seconds to days\n",
    "        candidate_times_mjd.append((fil_file, candidate_time_mjd))\n",
    "\n",
    "    return h5_file_names, h5_metadata, candidate_times_mjd, snr_list, dm_list, fil_start\n",
    "\n",
    "\n",
    "\n",
    "def mjd_to_datetime(mjd_tuple):\n",
    "    \"\"\"\n",
    "    Converts a Modified Julian Date (MJD) tuple to a datetime object.\n",
    "\n",
    "    Parameters:\n",
    "    mjd_tuple (tuple): Tuple containing (stuff, MJD value).\n",
    "\n",
    "    Returns:\n",
    "    datetime: Corresponding datetime object for the given MJD.\n",
    "    \"\"\"\n",
    "    mjd = mjd_tuple[1]\n",
    "    \n",
    "    return Time(mjd, format='mjd').datetime\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af08238-c6dc-46bc-842d-a216beccf083",
   "metadata": {},
   "source": [
    "### Funnction to save new sigmf files from a list of h5_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3831f7a-781f-4cda-893f-1a8f0adaf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_baseband_from_h5(h5_file_paths, output_dir, ram_data_dir, delta_t=1, snr_threshold=6):\n",
    "    \"\"\"\n",
    "    Processes HDF5 files to extract and save baseband data, applying time offsets\n",
    "    based on dispersion measures (DM) and signal-to-noise ratio (SNR) thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    h5_file_paths (list): List of paths to the HDF5 files.\n",
    "    output_dir (str): Directory to save the output baseband data.\n",
    "    ram_data_dir (str): Directory containing the SigMF metadata files.\n",
    "    delta_t (float, optional): Duration for the cropped data in seconds. Defaults to 1 second.\n",
    "    snr_threshold (float, optional): SNR threshold to filter candidates. Defaults to 6.\n",
    "\n",
    "    \"\"\"\n",
    "    bands = [\"PH_Band\", \"L1_Band\"]\n",
    "    ext = \".sigmf-meta\"\n",
    "    # Find candidate times in MJD and get metadata from HDF5 files\n",
    "    h5_file_names, h5_metadata, candidate_times_mjd, snr_list, dm_list, fil_start = find_candidate_time_in_mjd_get_meta(h5_file_paths)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for idx in range(len(h5_file_names)):\n",
    "        cand_time_mjd = candidate_times_mjd[idx]\n",
    "        snr = snr_list[idx]\n",
    "        dm = dm_list[idx]\n",
    "        metadata = h5_metadata[idx]\n",
    "        file_name = h5_file_names[idx]\n",
    "        dir_name, basename, tcand, dm, band, fil_file, fil_start = metadata\n",
    "\n",
    "        \n",
    "        print(f\"Processing h5 file: {file_name}\")\n",
    "        print(f\"Candidate time (MJD): {cand_time_mjd[1]} in band {band}, SNR: {snr}, DM: {dm}\")\n",
    "\n",
    "\n",
    "        if snr >= snr_threshold:\n",
    "            \n",
    "            for band_i in bands:\n",
    "                orig_files_primary = [f for f in os.listdir(ram_data_dir) if f.startswith(f\"{basename}_{band}\") and fil_start in f and f.endswith('.sigmf-meta')]\n",
    "                orig_files_secondary  = [f for f in os.listdir(ram_data_dir) if f.startswith(f\"{basename}_{band_i}\") and f.endswith('.sigmf-meta')]\n",
    "                \n",
    "                print(f'processing band {band_i}')\n",
    "                if band_i == band:\n",
    "                    # Processing the primary band\n",
    "                    for orig_file in orig_files_primary:\n",
    "                        orig_file_name = orig_file.replace(\".sigmf-meta\", \"\")\n",
    "                        new_file_name = f\"{basename}_{band_i}_{fil_start}_mjd_{cand_time_mjd[1]}_tcand_{tcand}_dm_{dm}_snr_{snr}.sigmf-meta\"\n",
    "                        input_metafilename = os.path.join(ram_data_dir, orig_file)\n",
    "                        output_metafilename = os.path.join(output_dir, new_file_name)\n",
    "\n",
    "                        # Read meta info from .sigmf\n",
    "                        sample_rate, center_freq, start_time, version = read_baseband_data(ram_data_dir, orig_file_name + ext)\n",
    "                        file_start_time_s = fromisoformat(start_time)  # datetime object\n",
    "                        \n",
    "                        # Ensure file_start_time_s is timezone-aware\n",
    "                        file_start_time_s = file_start_time_s.replace(tzinfo=pytz.UTC)\n",
    "                        \n",
    "                        candidate_dt = Time(cand_time_mjd[1], format='mjd').to_datetime()\n",
    "                        \n",
    "                        # Ensure candidate_dt is timezone-aware\n",
    "                        candidate_dt = candidate_dt.replace(tzinfo=pytz.UTC)\n",
    "                        \n",
    "                        time_difference = candidate_dt - file_start_time_s\n",
    "\n",
    "                        # Calculate start and duration for cropping\n",
    "                        seconds_difference = time_difference.total_seconds()\n",
    "                        start_s = seconds_difference - 0.5 * delta_t\n",
    "                        duration_s = delta_t\n",
    "\n",
    "                        print(f\"Cropping SigMF:\\n{input_metafilename} -> {output_metafilename}\")\n",
    "                        print(f\"Start: {start_s}s, Duration: {duration_s}s\")\n",
    "                        crop_sigmf(input_metafilename, output_metafilename, start_s, duration_s)\n",
    "\n",
    "                else:\n",
    "                    # Processing the secondary bands\n",
    "                    \n",
    "                    for j, orig_file in enumerate(orig_files_secondary):\n",
    "                        sigmf_file1 = f\"{basename}_{band}_{fil_start}\"\n",
    "                        sigmf_file2 = orig_file.replace(\".sigmf-meta\", \"\")\n",
    "    \n",
    "                        mjd_start2, time_offset = compute_time_offset(sigmf_file1, sigmf_file2, dm, cand_time_mjd, ram_data_dir)\n",
    "\n",
    "                        new_file_name = f\"{basename}_{band_i}_mjd_{mjd_start2[1]}_tcand_{float(tcand)+time_offset}_dm_{dm}_snr_{snr}\" \n",
    "                        input_metafilename = os.path.join(ram_data_dir, orig_file)\n",
    "                        output_metafilename = os.path.join(output_dir, new_file_name)\n",
    "\n",
    "                        # Read meta info from .sigmf\n",
    "                        sample_rate, center_freq, start_time, version = read_baseband_data(ram_data_dir, sigmf_file2 + ext)\n",
    "                        file_start_time_s = fromisoformat(start_time)  # datetime object\n",
    "                        \n",
    "                        # Ensure file_start_time_s is timezone-aware\n",
    "                        file_start_time_s = file_start_time_s.replace(tzinfo=pytz.UTC)\n",
    "                        \n",
    "                        candidate_dt = Time(cand_time_mjd[1], format='mjd').to_datetime()\n",
    "                        \n",
    "                        # Ensure candidate_dt is timezone-aware\n",
    "                        candidate_dt = candidate_dt.replace(tzinfo=pytz.UTC)\n",
    "                        \n",
    "                        time_difference = candidate_dt - file_start_time_s\n",
    "                       \n",
    "                        # Calculate start and duration for cropping\n",
    "                        seconds_difference = time_difference.total_seconds()\n",
    "                        start_s = seconds_difference - 0.5 * delta_t\n",
    "                        duration_s = delta_t\n",
    "\n",
    "                        output_metafilename += ext \n",
    "\n",
    "                        print(f\"Cropping SigMF:\\n{input_metafilename} -> {output_metafilename}\")\n",
    "                        print(f\"Start: {start_s}s, Duration: {duration_s}s\")\n",
    "                        crop_sigmf(input_metafilename, output_metafilename, start_s, duration_s)\n",
    "\n",
    "            print('\\n\\n\\n')\n",
    "\n",
    "        else:\n",
    "            print(f\"Rejected h5 file: {file_name} snr {snr} is less then baseband record threshold of {snr_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43518a21-d6d3-457b-a8ca-79c64b5b2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def delete_old_files(directory, time_del):\n",
    "    \"\"\"\n",
    "    Deletes files in the specified directory that are older than the given time delta.\n",
    "    \n",
    "    Parameters:\n",
    "    directory (str): Directory containing the files to delete.\n",
    "    time_del (timedelta): Time delta to determine the age of files to delete.\n",
    "    \"\"\"\n",
    "    current_time = time.time()\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_age = current_time - os.path.getmtime(file_path)\n",
    "            if file_age > time_del.total_seconds():\n",
    "                print(f\"Deleting old file: {file_path}\")\n",
    "               # os.remove(file_path)\n",
    "\n",
    "def process_baseband_h5_files(h5_file_paths, output_dir, ram_data_dir, delta_t=1, snr_threshold=6, time_del=timedelta(minutes=15)):\n",
    "    \"\"\"\n",
    "    Wrapper function to process HDF5 files and manage old files in RAM data directory.\n",
    "\n",
    "    Parameters:\n",
    "    h5_file_paths (list): List of paths to the HDF5 files.\n",
    "    output_dir (str): Directory to save the output baseband data.\n",
    "    ram_data_dir (str): Directory containing the SigMF metadata files.\n",
    "    delta_t (float, optional): Duration for the cropped data in seconds. Defaults to 1 second.\n",
    "    snr_threshold (float, optional): SNR threshold to filter candidates. Defaults to 6.\n",
    "    time_del (timedelta, optional): Time delta to determine the age of files to delete. Defaults to 5 min.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        save_baseband_from_h5(h5_file_paths, output_dir, ram_data_dir, delta_t, snr_threshold)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        delete_old_files(ram_data_dir, time_del)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed8603-f8cb-4532-853d-43b2f0016856",
   "metadata": {},
   "source": [
    "### Test Cell Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fc8295-c2de-477c-917e-12d3113fd024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing h5 file: /data/frb/2024-07-30/good/CRAB_PH_Band_2024_07_30_11_17_34_tcand_98.2247040_dm_56.9_snr_250.6.h5\n",
      "Candidate time (MJD): 60521.388428526676 in band PH_Band, SNR: 250.59, DM: 56.9\n",
      "processing band PH_Band\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_PH_Band_2024_07_30_11_17_34.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_PH_Band_2024_07_30_11_17_34_mjd_60521.388428526676_tcand_98.2247040_dm_56.9_snr_250.59.sigmf-meta\n",
      "Start: 86.427705s, Duration: 1s\n",
      "processing band L1_Band\n",
      "Correction in seconds: 0.001253602927781083\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_L1_Band_2024_07_30_11_17_34.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_L1_Band_mjd_60521.388428541184_tcand_98.22595760292778_dm_56.9_snr_250.59.sigmf-meta\n",
      "Start: 85.998205s, Duration: 1s\n",
      "Correction in seconds: 0.001253602927781083\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_L1_Band.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_L1_Band_mjd_60521.388428541184_tcand_98.22595760292778_dm_56.9_snr_250.59.sigmf-meta\n",
      "Start: 85.998205s, Duration: 1s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing h5 file: /data/frb/2024-07-30/good/CRAB_L1_Band_2024_07_30_11_17_34_tcand_85.0288830_dm_56.4_snr_32.8.h5\n",
      "Candidate time (MJD): 60521.38841468614 in band L1_Band, SNR: 32.82, DM: 56.4\n",
      "processing band PH_Band\n",
      "Correction in seconds: -0.0012425870848304583\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_PH_Band_2024_07_30_11_17_34.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_PH_Band_mjd_60521.388414671754_tcand_85.02764041291516_dm_56.4_snr_32.82.sigmf-meta\n",
      "Start: 85.231882s, Duration: 1s\n",
      "Correction in seconds: -0.0012425870848304583\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_PH_Band.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_PH_Band_mjd_60521.388414671754_tcand_85.02764041291516_dm_56.4_snr_32.82.sigmf-meta\n",
      "Start: 85.231882s, Duration: 1s\n",
      "processing band L1_Band\n",
      "Cropping SigMF:\n",
      "/data_tmp/CRAB_L1_Band_2024_07_30_11_17_34.sigmf-meta -> /data/frb/maxfinetmp/test_baseband/CRAB_L1_Band_2024_07_30_11_17_34_mjd_60521.38841468614_tcand_85.0288830_dm_56.4_snr_32.82.sigmf-meta\n",
      "Start: 84.802382s, Duration: 1s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deleting old file: /data_tmp/CRAB_PH_Band_2024_07_30_11_17_34.sigmf-meta\n",
      "Deleting old file: /data_tmp/CRAB_PH_Band_2024_07_30_11_17_34.sigmf-data\n",
      "Deleting old file: /data_tmp/CRAB_L1_Band_2024_07_30_11_17_34.sigmf-meta\n",
      "Deleting old file: /data_tmp/CRAB_L1_Band_2024_07_30_11_17_34.sigmf-data\n",
      "Deleting old file: /data_tmp/tammotest.sigmf-data\n",
      "Deleting old file: /data_tmp/tammotest.sigmf-meta\n",
      "Deleting old file: /data_tmp/CRAB_L1_Band.sigmf-meta\n",
      "Deleting old file: /data_tmp/CRAB_PH_Band.sigmf-meta\n",
      "Deleting old file: /data_tmp/CRAB_PH_Band.sigmf-data\n",
      "Deleting old file: /data_tmp/CRAB_L1_Band.sigmf-data\n"
     ]
    }
   ],
   "source": [
    "h5_files = ['CRAB_L1_Band_2024_07_30_11_17_34_tcand_85.0288830_dm_56.4_snr_32.8.h5',\n",
    "            'CRAB_PH_Band_2024_07_30_11_17_34_tcand_98.2247040_dm_56.9_snr_250.6.h5']\n",
    "\n",
    "good_dir = '/data/frb/2024-07-30/good/'\n",
    "h5_file_paths = [good_dir + h5_files[1], good_dir + h5_files[0]]\n",
    "#print(h5_file_paths)\n",
    "output_dir = \"/data/frb/maxfinetmp/test_baseband\"\n",
    "ram_data_dir = \"/data_tmp\"\n",
    "\n",
    "# Call the function\n",
    "process_baseband_h5_files(h5_file_paths, output_dir, ram_data_dir, delta_t=1, snr_threshold=6, time_del=timedelta(minutes=15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667665e-102c-4ab2-89ef-cfa0c3a5ebe0",
   "metadata": {},
   "source": [
    "### Test with importing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2026517-4530-4542-a7da-3266dd7a3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_baseband_utils import process_baseband_h5_files\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "h5_files = ['CRAB_L1_Band_2024_07_30_11_17_34_tcand_85.0288830_dm_56.4_snr_32.8.h5',\n",
    "            'CRAB_PH_Band_2024_07_30_11_17_34_tcand_98.2247040_dm_56.9_snr_250.6.h5']\n",
    "\n",
    "good_dir = '/data/frb/2024-07-30/good/'\n",
    "h5_file_paths = [good_dir + h5_files[1], good_dir + h5_files[0]]\n",
    "#print(h5_file_paths)\n",
    "output_dir = \"/data/frb/maxfinetmp/test_baseband\"\n",
    "ram_data_dir = \"/data_tmp\"\n",
    "\n",
    "process_baseband_h5_files(h5_file_paths, output_dir, ram_data_dir, delta_t=1, snr_threshold=6, time_del=timedelta(minutes=15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194a8f9-ef21-4e7a-a5bb-9e4262246ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30ce637-4958-4a16-9722-7a96f9a724dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7335f64-bc6a-45d4-b012-bf6e7d2dce35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8935af-8e78-4dfd-82bf-918febc50f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15c51b-c0b3-4b16-9f19-0c67cc018cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5a63e-1c77-464b-aaaf-1d0007ffa11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407617b-a24c-4171-aaec-0eb7b377c0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cfd2f-0517-41bb-8c12-c70d77e606f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
